{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (23322, 2)\n",
      "                                            Sentence  Label\n",
      "0  Geisingen Kirchen-Hausen first documented toge...      0\n",
      "1      The victim later died result serious injuries      0\n",
      "2  Aircraft electronic device rules stay force Au...      0\n",
      "3  The problem known administrative department in...      0\n",
      "4  The specific figures must calculated municipal...      0\n",
      "After dropping missing values: (23322, 2)\n",
      "\n",
      "Training set size: 16325\n",
      "Test set size: 6997\n",
      "\n",
      "Training label distribution:\n",
      "Safe (0): 8568\n",
      "Malicious (1): 7757\n",
      "\n",
      "Test label distribution:\n",
      "Safe (0): 3655\n",
      "Malicious (1): 3342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/desireegomez/Desktop/TFProj/tfvenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/desireegomez/Desktop/TFProj/tfvenv/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorization: X_train_vect shape: (16325, 20000) | X_test_vect shape: (6997, 20000)\n",
      "After SMOTE: Resampled training set size: 17136 | Test set size remains: 6997\n",
      "Preprocessing complete and vectorizer saved!\n",
      "Vectorizer Vocabulary Size: 20000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "# Custom tokenizer to remove unwanted characters and tokenize the text\n",
    "def custom_tokenizer(text):\n",
    "    # Space out special characters \n",
    "    text = re.sub(r\"(['\\\";=])\", r\" \\1 \", text)  \n",
    "    text = re.sub(r\"--\", \" -- \", text)          \n",
    "    text = re.sub(r\"\\s+\", \" \", text)            \n",
    "    text = text.lower()\n",
    "    return text.strip().split()\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('balanced.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values and drop rows where 'Sentence' column is NaN\n",
    "df.dropna(subset=['Sentence'], inplace=True)\n",
    "print(f\"After dropping missing values: {df.shape}\")\n",
    "\n",
    "# Ensure all 'Sentence' entries are strings \n",
    "df['Sentence'] = df['Sentence'].astype(str)\n",
    "\n",
    "# Define the feature (X) and label (y)\n",
    "X = df['Sentence']\n",
    "y = df['Label']\n",
    "\n",
    "# Split the data into training and testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "# Count the number of samples in training and test sets\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Count labels in the training set\n",
    "train_label_counts = y_train.value_counts()\n",
    "print(\"\\nTraining label distribution:\")\n",
    "print(f\"Safe (0): {train_label_counts.get(0, 0)}\")\n",
    "print(f\"Malicious (1): {train_label_counts.get(1, 0)}\")\n",
    "\n",
    "# Count labels in the test set\n",
    "test_label_counts = y_test.value_counts()\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(f\"Safe (0): {test_label_counts.get(0, 0)}\")\n",
    "print(f\"Malicious (1): {test_label_counts.get(1, 0)}\")\n",
    "\n",
    "# Initialize the TfidfVectorizer with the custom tokenizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, max_features=20000)\n",
    "\n",
    "# Fit and transform the training data, and transform the test data\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Print the shape of the resulting feature matrices\n",
    "print(f\"After vectorization: X_train_vect shape: {X_train_vect.shape} | X_test_vect shape: {X_test_vect.shape}\")\n",
    "\n",
    "# Apply SMOTE to balance the training set (handling class imbalance)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_vect, y_train)\n",
    "\n",
    "# Print the size of the resampled training set\n",
    "print(f\"After SMOTE: Resampled training set size: {X_train_resampled.shape[0]} | Test set size remains: {X_test_vect.shape[0]}\")\n",
    "\n",
    "# Save the preprocessed data and the vectorizer for later use\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "joblib.dump(X_train_resampled, 'X_train_resampled.pkl')\n",
    "joblib.dump(y_train_resampled, 'y_train_resampled.pkl')\n",
    "joblib.dump(X_test_vect, 'X_test_vect.pkl')\n",
    "joblib.dump(y_test, 'y_test.pkl')\n",
    "\n",
    "# Print information about the vectorizer\n",
    "print(f\"Preprocessing complete and vectorizer saved!\")\n",
    "print(f\"Vectorizer Vocabulary Size: {len(vectorizer.get_feature_names_out())}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
